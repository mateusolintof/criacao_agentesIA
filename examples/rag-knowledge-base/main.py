"""
Exemplo: RAG Knowledge Base com AGNO

Sistema de Q&A sobre base de conhecimento usando Retrieval-Augmented Generation.
Framework: AGNO
Atualizado: 2025-11-20
"""

import os
import sys
from dotenv import load_dotenv
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb
from agno.tools.toolkit import Toolkit

from vector_store import VectorStore
from knowledge_loader import KnowledgeLoader

# Carregar vari√°veis de ambiente
load_dotenv()


class KnowledgeToolkit(Toolkit):
    """Toolkit para busca na base de conhecimento."""
    
    def __init__(self, vector_store: VectorStore, top_k: int = 3):
        super().__init__(name="knowledge_toolkit")
        self.vector_store = vector_store
        self.top_k = top_k
        
        # Registrar fun√ß√µes
        self.register(self.search_knowledge)
    
    def search_knowledge(self, query: str) -> str:
        """
        Busca informa√ß√µes relevantes na base de conhecimento.
        
        Args:
            query: Pergunta ou termo de busca
        
        Returns:
            Documentos relevantes encontrados
        """
        results = self.vector_store.search(query, top_k=self.top_k)
        
        if not results:
            return "N√£o encontrei informa√ß√µes relevantes sobre isso na base de conhecimento."
        
        # Formatar resultados
        formatted = "üìö Informa√ß√µes encontradas na base de conhecimento:\n\n"
        for i, result in enumerate(results, 1):
            formatted += f"--- Documento {i} ---\n"
            formatted += f"Fonte: {result['metadata'].get('filename', 'unknown')}\n"
            formatted += f"Conte√∫do:\n{result['document']}\n\n"
        
        return formatted


def initialize_knowledge_base() -> VectorStore:
    """Inicializa e carrega a base de conhecimento."""
    
    # Configurar vector store
    persist_dir = os.getenv("CHROMA_PERSIST_DIR", "./tmp/chroma_db")
    embedding_model = os.getenv("EMBEDDING_MODEL", "all-MiniLM-L6-v2")
    vector_store = VectorStore(
        persist_dir=persist_dir,
        collection_name="knowledge_base",
        embedding_model=embedding_model
    )
    
    # Verificar se j√° tem documentos
    if vector_store.count() > 0:
        print(f"‚úÖ Base de conhecimento j√° carregada ({vector_store.count()} chunks)")
        return vector_store
    
    print("üìö Carregando base de conhecimento...")
    
    # Configurar loader
    chunk_size = int(os.getenv("CHUNK_SIZE", "1000"))
    chunk_overlap = int(os.getenv("CHUNK_OVERLAP", "200"))
    loader = KnowledgeLoader(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    
    # Carregar documentos da pasta sample_docs
    docs_dir = os.path.join(os.path.dirname(__file__), "sample_docs")
    if not os.path.exists(docs_dir):
        print(f"‚ö†Ô∏è  Diret√≥rio {docs_dir} n√£o encontrado. Criando vazio...")
        os.makedirs(docs_dir, exist_ok=True)
        return vector_store
    
    # Carregar e processar documentos
    documents = loader.load_directory(docs_dir)
    
    if not documents:
        print("‚ö†Ô∏è  Nenhum documento encontrado em sample_docs/")
        return vector_store
    
    # Adicionar ao vector store
    texts = [doc['text'] for doc in documents]
    metadatas = [doc['metadata'] for doc in documents]
    ids = [f"{doc['metadata']['filename']}_{doc['metadata']['chunk']}" for doc in documents]
    
    vector_store.add_documents(texts, metadatas, ids)
    
    print(f"‚úÖ {len(documents)} chunks adicionados √† base de conhecimento")
    
    return vector_store


def create_agent(vector_store: VectorStore) -> Agent:
    """Cria o agente AGNO com RAG."""
    
    # Configurar database para hist√≥rico
    db_file = os.getenv("AGNO_DB_FILE", "./tmp/rag_memory.db")
    os.makedirs(os.path.dirname(db_file) if os.path.dirname(db_file) else "./tmp", exist_ok=True)
    
    db = SqliteDb(
        session_table="rag_sessions",
        db_file=db_file
    )
    
    # Criar toolkit de conhecimento
    top_k = int(os.getenv("TOP_K_RESULTS", "3"))
    knowledge_toolkit = KnowledgeToolkit(vector_store, top_k=top_k)
    
    # Instru√ß√µes do agente (lista de strings - padr√£o AGNO)
    instructions = [
        "Voc√™ √© um assistente especializado em responder perguntas sobre nossa base de conhecimento.",
        "",
        "REGRAS IMPORTANTES:",
        "1. SEMPRE use a fun√ß√£o 'search_knowledge' para buscar informa√ß√µes antes de responder",
        "2. Base suas respostas APENAS nas informa√ß√µes encontradas na base de conhecimento",
        "3. Se n√£o encontrar informa√ß√µes relevantes, seja honesto e diga que n√£o sabe",
        "4. NUNCA invente ou alucinne informa√ß√µes que n√£o est√£o na base",
        "5. Cite a fonte quando poss√≠vel (nome do documento)",
        "6. Se a pergunta for amb√≠gua, pe√ßa esclarecimentos",
        "",
        "ESTILO DE RESPOSTA:",
        "- Seja claro, direto e profissional",
        "- Use formata√ß√£o markdown quando apropriado",
        "- Para informa√ß√µes t√©cnicas, seja preciso",
        "- Para pre√ßos e datas, sempre cite a fonte e data de atualiza√ß√£o",
        "",
        "LIMITA√á√ïES:",
        "- Voc√™ s√≥ tem acesso √† base de conhecimento carregada",
        "- N√£o tem informa√ß√µes em tempo real",
        "- Para quest√µes fora da base, direcione ao contato apropriado"
    ]
    
    # Criar agente AGNO
    agent = Agent(
        name=os.getenv("AGNO_AGENT_NAME", "Knowledge Assistant"),
        model=OpenAIChat(
            id=os.getenv("OPENAI_MODEL", "gpt-4-turbo"),
            temperature=float(os.getenv("OPENAI_TEMPERATURE", "0.7"))
        ),
        db=db,
        tools=[knowledge_toolkit],
        add_history_to_context=True,
        num_history_runs=int(os.getenv("AGNO_NUM_HISTORY_RUNS", "3")),
        instructions=instructions,
        markdown=True,
        show_tool_calls=True,  # Mostrar quando usa a busca
    )
    
    return agent


def main():
    """Fun√ß√£o principal."""
    
    # Verificar API key
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå Erro: OPENAI_API_KEY n√£o configurada.")
        print("Configure no arquivo .env")
        sys.exit(1)
    
    print("\n" + "="*70)
    print("üìö  RAG KNOWLEDGE BASE - AGNO")
    print("="*70)
    print("\nSistema de perguntas e respostas sobre base de conhecimento")
    print("usando Retrieval-Augmented Generation (RAG)")
    print("\nDigite 'sair' para encerrar, 'limpar' para nova sess√£o.\n")
    
    # Inicializar base de conhecimento
    print("Inicializando sistema...")
    vector_store = initialize_knowledge_base()
    
    # Criar agente
    agent = create_agent(vector_store)
    print("‚úÖ Sistema pronto!\n")
    
    # Gerar session_id √∫nico
    import time
    session_id = f"rag_session_{int(time.time())}"
    
    # Loop de conversa√ß√£o
    while True:
        try:
            # Input do usu√°rio
            user_input = input("üë§ Voc√™: ").strip()
            
            # Verificar comandos
            if user_input.lower() in ["sair", "quit", "exit", "q"]:
                print("\nüëã Encerrando. At√© logo!")
                break
            
            if user_input.lower() == "limpar":
                session_id = f"rag_session_{int(time.time())}"
                print("üîÑ Nova sess√£o iniciada!\n")
                continue
            
            if not user_input:
                continue
            
            # Processar com agente
            print("\nü§ñ Assistente: ", end="", flush=True)
            
            # Usar streaming para resposta em tempo real
            response = agent.run(
                user_input,
                session_id=session_id,
                stream=True
            )
            
            # Stream de resposta
            for chunk in response:
                print(chunk, end="", flush=True)
            
            print("\n")
            
        except KeyboardInterrupt:
            print("\n\nüëã Interrompido. At√© logo!")
            break
        except Exception as e:
            print(f"\n‚ùå Erro: {e}")
            print("Continuando...\n")


if __name__ == "__main__":
    main()
