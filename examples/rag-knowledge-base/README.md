# Exemplo: RAG Knowledge Base com AGNO

Sistema completo de **Q&A sobre base de conhecimento** usando **Retrieval-Augmented Generation (RAG)** com AGNO.

**Framework:** AGNO  
**Vector Database:** ChromaDB  
**Embeddings:** Sentence-Transformers  
**Atualizado:** 2025-11-20

## ğŸ¯ Objetivo

Demonstrar como criar um sistema RAG que:
- **Carrega** documentos de vÃ¡rias fontes (MD, PDF, TXT, HTML)
- **Processa** e divide em chunks inteligentes
- **Indexa** usando embeddings vetoriais
- **Responde** perguntas baseado apenas no conhecimento carregado
- **Previne** alucinaÃ§Ãµes (hallucination prevention)

## ğŸ—ï¸ Arquitetura

```
User Question
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AGNO Agent            â”‚
â”‚  (GPT-4 Turbo)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€> search_knowledge(query)
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Vector Store   â”‚
    â”‚ (ChromaDB)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€> Similarity Search
            â”‚   (Top K documents)
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Embeddings    â”‚
    â”‚ (all-MiniLM)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    Retrieved Documents
            â”‚
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ AGNO Agent      â”‚
    â”‚ Synthesizes     â”‚
    â”‚ Final Answer    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estrutura

```
rag-knowledge-base/
â”œâ”€â”€ README.md              # Este arquivo
â”œâ”€â”€ main.py                # Sistema RAG completo
â”œâ”€â”€ vector_store.py        # IntegraÃ§Ã£o com ChromaDB
â”œâ”€â”€ knowledge_loader.py    # Processamento de documentos
â”œâ”€â”€ sample_docs/           # Documentos de exemplo
â”‚   â”œâ”€â”€ produto_crm.md
â”‚   â”œâ”€â”€ produto_ai_assistant.md
â”‚   â””â”€â”€ processo_vendas.md
â”œâ”€â”€ .env.example           # VariÃ¡veis de ambiente
â””â”€â”€ requirements.txt       # DependÃªncias especÃ­ficas
```

## ğŸš€ Setup

### 1. Instalar dependÃªncias

```bash
# Na raiz do projeto ou neste diretÃ³rio
pip install agno openai chromadb sentence-transformers pypdf python-dotenv beautifulsoup4 markdown

# Ou
pip install -r requirements.txt
```

### 2. Configurar ambiente

```bash
cd examples/rag-knowledge-base
cp .env.example .env
# Editar .env com sua OPENAI_API_KEY
```

### 3. Adicionar documentos

Coloque seus documentos na pasta `sample_docs/`:
- Formatos suportados: `.md`, `.txt`, `.pdf`, `.html`
- JÃ¡ incluÃ­mos 3 documentos de exemplo

### 4. Executar

```bash
python main.py
```

Na primeira execuÃ§Ã£o:
- CarregarÃ¡ todos documentos de `sample_docs/`
- GerarÃ¡ embeddings (pode demorar alguns segundos)
- SalvarÃ¡ no ChromaDB (persistente)

ExecuÃ§Ãµes seguintes serÃ£o instantÃ¢neas (usa cache).

## ğŸ’¬ Exemplos de Uso

### Exemplo 1: Pergunta sobre Produto

```
ğŸ‘¤ VocÃª: Quanto custa o CRM Enterprise?

ğŸ¤– Assistente:
[Busca na base de conhecimento...]

O CRM Enterprise custa **R$ 199 por usuÃ¡rio/mÃªs**.

Fonte: produto_crm.md

AlÃ©m disso, hÃ¡ outras opÃ§Ãµes:
- **AI Assistant:** R$ 499/mÃªs (conversas ilimitadas)
- **Analytics Suite:** R$ 299/mÃªs

Gostaria de saber mais sobre algum desses produtos?
```

### Exemplo 2: Pergunta TÃ©cnica

```
ğŸ‘¤ VocÃª: Como funciona a qualificaÃ§Ã£o de leads no processo BANT?

ğŸ¤– Assistente:
[Busca na base de conhecimento...]

A metodologia **BANT** qualifica leads em 4 dimensÃµes:

**B - Budget (OrÃ§amento)**
- Verificar se hÃ¡ orÃ§amento alocado
- CritÃ©rio: >= R$ 1.000/mÃªs para CRM, >= R$ 500/mÃªs para AI Assistant

**A - Authority (Autoridade)**
- Identificar quem toma a decisÃ£o
- Ideal: Decisor direto (CEO, Diretor)

**N - Need (Necessidade)**
- Entender problema especÃ­fico
- Verificar urgÃªncia e impacto no negÃ³cio

**T - Timeline (Prazo)**
- Mapear quando precisam implementar
- Urgente (< 30 dias) tem prioridade

Fonte: processo_vendas.md (atualizado 2025-11-20)
```

### Exemplo 3: ComparaÃ§Ã£o de Produtos

```
ğŸ‘¤ VocÃª: Qual a diferenÃ§a entre CRM Enterprise e AI Assistant?

ğŸ¤– Assistente:
[Busca na base de conhecimento...]

**CRM Enterprise (R$ 199/usuÃ¡rio/mÃªs):**
- GestÃ£o de pipeline de vendas
- AutomaÃ§Ã£o de follow-ups
- RelatÃ³rios avanÃ§ados
- **Ideal para:** Equipes de vendas de 5-100 pessoas
- **ImplementaÃ§Ã£o:** 4-6 semanas

**AI Assistant (R$ 499/mÃªs):**
- QualificaÃ§Ã£o automÃ¡tica de leads 24/7
- Atendimento multi-canal (WhatsApp, chat, Messenger)
- Conversas ilimitadas
- **Ideal para:** Alto volume de leads (100+ por mÃªs)
- **ImplementaÃ§Ã£o:** 7-10 dias

**Podem ser usados juntos:** AI Assistant qualifica leads automaticamente e integra com CRM Enterprise para gestÃ£o do pipeline.

Fontes: produto_crm.md, produto_ai_assistant.md
```

### Exemplo 4: Pergunta Fora da Base

```
ğŸ‘¤ VocÃª: Qual a previsÃ£o do tempo para amanhÃ£?

ğŸ¤– Assistente:
[Busca na base de conhecimento...]

Desculpe, nÃ£o encontrei informaÃ§Ãµes sobre previsÃ£o do tempo na minha base de conhecimento. 

Minha expertise estÃ¡ focada em:
- Produtos (CRM Enterprise, AI Assistant, Analytics Suite)
- Processos de venda (metodologia BANT)
- ImplementaÃ§Ã£o e suporte

Posso ajudar com alguma dessas Ã¡reas?
```

## ğŸ”‘ Conceitos-Chave

### RAG (Retrieval-Augmented Generation)

RAG combina:
1. **Retrieval:** Busca documentos relevantes no vector store
2. **Augmentation:** Adiciona documentos ao contexto do LLM
3. **Generation:** LLM gera resposta baseada nos documentos

**Vantagens:**
- âœ… Respostas baseadas em fatos (nÃ£o inventa)
- âœ… Sempre atualizado (basta recarregar documentos)
- âœ… Cita fontes (rastreabilidade)
- âœ… Menor custo (menos tokens que fine-tuning)

### Embeddings

Vetores numÃ©ricos que representam significado semÃ¢ntico:
- Textos similares tÃªm embeddings prÃ³ximos
- Permite busca por similaridade (nÃ£o apenas keywords)
- Modelo usado: `all-MiniLM-L6-v2` (rÃ¡pido e eficiente)

### Chunking

DivisÃ£o de documentos em pedaÃ§os menores:
- **Chunk size:** 1000 caracteres (configurÃ¡vel)
- **Overlap:** 200 caracteres (mantÃ©m contexto entre chunks)
- Chunks menores = mais precisÃ£o, mas pode perder contexto
- Chunks maiores = mais contexto, mas menos preciso

### AGNO Toolkit

Custom tools para o agente:
```python
class KnowledgeToolkit(Toolkit):
    def search_knowledge(self, query: str) -> str:
        """Busca na base de conhecimento"""
        results = self.vector_store.search(query, top_k=3)
        return formatted_results
```

Agente decide quando usar a ferramenta automaticamente.

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar Qualidade da Busca

No `.env`:
```bash
# Mais resultados = mais contexto, mas pode incluir irrelevantes
TOP_K_RESULTS=5  # PadrÃ£o: 3

# Chunks maiores = mais contexto por resultado
CHUNK_SIZE=1500  # PadrÃ£o: 1000
CHUNK_OVERLAP=300  # PadrÃ£o: 200
```

### Usar Modelo de Embeddings Diferente

```bash
# Modelos disponÃ­veis: https://huggingface.co/sentence-transformers

# Mais preciso (mas mais lento)
EMBEDDING_MODEL=all-mpnet-base-v2

# Multilingual (melhor para portuguÃªs)
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2

# Mais rÃ¡pido (mas menos preciso)
EMBEDDING_MODEL=all-MiniLM-L6-v2  # PadrÃ£o
```

### Filtrar por Metadata

```python
# No vector_store.py, adicionar filtros
results = vector_store.search(
    query="preÃ§os",
    top_k=3,
    where={"filename": "produto_crm.md"}  # Buscar apenas neste arquivo
)
```

### Reprocessar Base de Conhecimento

```python
# Limpar e recarregar
from vector_store import VectorStore

vector_store = VectorStore()
vector_store.clear()  # Remove todos documentos

# Executar main.py novamente para recarregar
```

## ğŸ”§ Troubleshooting

**Erro: "No module named 'sentence_transformers'"**
```bash
SoluÃ§Ã£o: pip install sentence-transformers
```

**Erro: "ChromaDB not found"**
```bash
SoluÃ§Ã£o: pip install chromadb
```

**Respostas imprecisas ou irrelevantes**
```
SoluÃ§Ã£o 1: Aumentar TOP_K_RESULTS (mais documentos)
SoluÃ§Ã£o 2: Melhorar qualidade dos documentos de origem
SoluÃ§Ã£o 3: Ajustar CHUNK_SIZE (testar valores diferentes)
SoluÃ§Ã£o 4: Usar modelo de embedding melhor (multilingual)
```

**Sistema muito lento**
```
SoluÃ§Ã£o 1: Modelo de embedding estÃ¡ sendo baixado (primeira vez)
SoluÃ§Ã£o 2: Usar modelo menor (all-MiniLM-L6-v2)
SoluÃ§Ã£o 3: Reduzir TOP_K_RESULTS
```

**Agente inventa informaÃ§Ãµes (hallucination)**
```
SoluÃ§Ã£o: Melhorar instruÃ§Ãµes do agente
- ReforÃ§ar: "APENAS informaÃ§Ãµes da base"
- Adicionar: "Se nÃ£o sabe, diga que nÃ£o sabe"
- Revisar: show_tool_calls=True para verificar se estÃ¡ buscando
```

## ğŸ“Š MÃ©tricas de Performance

### Tempo de Resposta
- **Primeira pergunta:** 3-5s (inclui busca vetorial + LLM)
- **Perguntas seguintes:** 2-3s (cache de embeddings)

### Custos (OpenAI)
- **Por pergunta:** ~$0.01 - $0.03 (depende do tamanho dos chunks)
- **Embeddings:** Gratuito (modelo local)
- **Vector DB:** Gratuito (ChromaDB open-source)

### Qualidade
- **PrecisÃ£o:** > 90% (se documentos bem escritos)
- **Recall:** > 85% (encontra documentos relevantes)
- **Hallucination rate:** < 5% (com instruÃ§Ãµes corretas)

## ğŸ†š Quando Usar RAG

### Use RAG quando:
âœ… ConteÃºdo muda frequentemente  
âœ… Grande volume de documentaÃ§Ã£o  
âœ… Necessita citar fontes  
âœ… Quer evitar alucinaÃ§Ãµes  
âœ… InformaÃ§Ãµes proprietÃ¡rias/confidenciais

### Use Fine-tuning quando:
âœ… ConteÃºdo estÃ¡vel  
âœ… Mudar estilo/tom do modelo  
âœ… DomÃ­nio muito especÃ­fico  
âœ… Performance crÃ­tica (latÃªncia)

### Use Prompts simples quando:
âœ… Conhecimento estÃ¡ no modelo base  
âœ… Tarefa genÃ©rica  
âœ… Budget limitado  
âœ… Simplicidade Ã© prioridade

## ğŸ“š PrÃ³ximos Passos

1. âœ… Teste com seus prÃ³prios documentos
2. Adicione mais fontes (APIs, databases, web scraping)
3. Implemente cache de respostas (Redis)
4. Adicione feedback loop (ğŸ‘ğŸ‘ para melhorar)
5. Configure re-ranking para melhor precisÃ£o
6. Adicione autenticaÃ§Ã£o e controle de acesso

## ğŸ”— Exemplos Relacionados

- **Simple Chatbot (AGNO):** `examples/simple-chatbot/`
- **Multi-Agent Sales (CrewAI):** `examples/multi-agent-sales/`
- **API Integration (AGNO):** `examples/api-integration-agno/`

## ğŸ“– ReferÃªncias

- **AGNO Docs:** https://docs.agno.com
- **ChromaDB Docs:** https://docs.trychroma.com
- **Sentence-Transformers:** https://www.sbert.net
- **RAG Pattern:** https://arxiv.org/abs/2005.11401
