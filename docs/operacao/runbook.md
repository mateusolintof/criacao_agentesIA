# Runbook Operacional - Agente de IA

**Vers√£o:** 1.0
**√öltima Atualiza√ß√£o:** 2024-01-20
**P√∫blico-Alvo:** Engenheiros On-Call, DevOps, SRE
**Tempo M√©dio de Leitura:** 20 minutos

---

## √çndice R√°pido

1. [Vis√£o Geral do Sistema](#1-vis√£o-geral-do-sistema)
2. [Arquitetura R√°pida](#2-arquitetura-r√°pida)
3. [Opera√ß√µes Comuns](#3-opera√ß√µes-comuns)
4. [Procedimentos de Incidente](#4-procedimentos-de-incidente)
5. [Guia de Troubleshooting](#5-guia-de-troubleshooting)
6. [Monitoramento e Alertas](#6-monitoramento-e-alertas)
7. [Tarefas de Manuten√ß√£o](#7-tarefas-de-manuten√ß√£o)
8. [Procedimentos de Emerg√™ncia](#8-procedimentos-de-emerg√™ncia)
9. [Escala√ß√£o](#9-escala√ß√£o)
10. [Runbooks Espec√≠ficos](#10-runbooks-espec√≠ficos)
11. [Checklist de On-Call](#11-checklist-de-on-call)
12. [Contatos e Recursos](#12-contatos-e-recursos)

---

## 1. Vis√£o Geral do Sistema

### 1.1 O que √© o Sistema?

Sistema de agentes de IA conversacionais para atendimento comercial, capaz de:
- Qualificar leads automaticamente
- Responder perguntas sobre produtos/servi√ßos
- Escalar para atendimento humano quando necess√°rio
- Integrar com CRM, email e outras ferramentas

### 1.2 Componentes Principais

| Componente | Fun√ß√£o | Tecnologia | Criticidade |
|------------|--------|------------|-------------|
| **Agent API** | API principal do agente | FastAPI + Uvicorn | CR√çTICO |
| **PostgreSQL** | Banco de dados principal | PostgreSQL 15 | CR√çTICO |
| **Redis** | Cache e sess√µes | Redis 7 | CR√çTICO |
| **LLM Provider** | Gera√ß√£o de respostas | OpenAI/Anthropic | CR√çTICO |
| **CRM Integration** | Sincroniza√ß√£o de leads | Salesforce/HubSpot | ALTO |
| **Email Service** | Envio de emails | SendGrid | M√âDIO |
| **Monitoring** | Observabilidade | Prometheus + Grafana | ALTO |

### 1.3 SLAs e M√©tricas-Alvo

| M√©trica | Target | P95 | P99 |
|---------|--------|-----|-----|
| **Uptime** | 99.5% | - | - |
| **Response Time** | <1s | <2s | <3s |
| **Error Rate** | <0.5% | <1% | <2% |
| **Intent Accuracy** | >90% | >85% | >80% |
| **CSAT** | >4.0/5 | >3.5/5 | >3.0/5 |

### 1.4 Ambientes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Development ‚îÇ -> ‚îÇ    Test     ‚îÇ -> ‚îÇ   Staging   ‚îÇ -> ‚îÇ Production  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   Local               CI/CD          Prod-like          Real Users
```

**URLs:**
- Development: `http://localhost:8000`
- Test: `https://test-api.example.com`
- Staging: `https://staging-api.example.com`
- Production: `https://api.example.com`

---

## 2. Arquitetura R√°pida

### 2.1 Diagrama de Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    USU√ÅRIOS                          ‚îÇ
‚îÇ        (Web Chat, WhatsApp, API, Email)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              API GATEWAY (Nginx/ALB)                 ‚îÇ
‚îÇ  - Auth, Rate Limiting, Load Balancing               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            AGENT API (FastAPI)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇRouter Agent ‚îÇ --> ‚îÇ Specialized Agents       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ - Sales, Support, etc    ‚îÇ   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò
             ‚îÇ                     ‚îÇ                 ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ  PostgreSQL  ‚îÇ    ‚îÇ    Redis     ‚îÇ   ‚îÇ  LLM API   ‚îÇ
     ‚îÇ  (Dados)     ‚îÇ    ‚îÇ   (Cache)    ‚îÇ   ‚îÇ (OpenAI)   ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                     ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ        INTEGRATIONS                ‚îÇ
     ‚îÇ  CRM | Email | Calendar | Analytics‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2 Fluxo de Requisi√ß√£o

```
1. User ‚Üí API Gateway
   ‚îî‚îÄ> Auth check
   ‚îî‚îÄ> Rate limit check
   ‚îî‚îÄ> Route to Agent API

2. Agent API ‚Üí Process Request
   ‚îî‚îÄ> Validate input (guardrails)
   ‚îî‚îÄ> Load context from Redis/PostgreSQL
   ‚îî‚îÄ> Router Agent classifica intent
   ‚îî‚îÄ> Delega para Specialized Agent

3. Specialized Agent ‚Üí Generate Response
   ‚îî‚îÄ> Build prompt com context
   ‚îî‚îÄ> Call LLM API
   ‚îî‚îÄ> Execute tools (se necess√°rio)
   ‚îî‚îÄ> Apply guardrails

4. Store & Integrate
   ‚îî‚îÄ> Update memory (Redis + PostgreSQL)
   ‚îî‚îÄ> Sync com CRM (se lead qualificado)
   ‚îî‚îÄ> Log interaction

5. Return Response ‚Üí User
```

### 2.3 Pontos de Falha Comuns

| Componente | Impacto se Falhar | Fallback |
|------------|-------------------|----------|
| Agent API Down | Sistema inoperante | Mensagem de manuten√ß√£o |
| PostgreSQL Down | Sistema inoperante | Nenhum (cr√≠tico) |
| Redis Down | Performance degradada | Continua sem cache |
| LLM API Down | Sem respostas IA | Fallback para respostas pre-programadas |
| CRM API Down | Leads n√£o sincronizam | Fila de retry + sync posterior |

**Refer√™ncia Completa:** `/docs/arquitetura.md`

---

## 3. Opera√ß√µes Comuns

### 3.1 Start/Stop do Sistema

#### Iniciar Sistema (Production)

```bash
# 1. Verificar pr√©-requisitos
./scripts/preflight-check.sh

# 2. Iniciar depend√™ncias (se n√£o gerenciadas)
sudo systemctl start postgresql
sudo systemctl start redis

# 3. Verificar status das depend√™ncias
sudo systemctl status postgresql
sudo systemctl status redis

# 4. Iniciar aplica√ß√£o
# Op√ß√£o A: systemd
sudo systemctl start agente-api

# Op√ß√£o B: Docker Compose
docker-compose -f docker-compose.prod.yml up -d

# Op√ß√£o C: Kubernetes
kubectl apply -f k8s/production/

# 5. Verificar sa√∫de
curl https://api.example.com/health
# Esperado: {"status": "healthy", "version": "1.2.3"}

# 6. Verificar logs
sudo journalctl -u agente-api -f
# Ou
docker logs -f agente-api
# Ou
kubectl logs -f deployment/agente-api

# 7. Validar m√©tricas
curl https://api.example.com/metrics | grep agent_requests_total
```

#### Parar Sistema (Gracefully)

```bash
# 1. Ativar modo manuten√ß√£o (opcional)
./scripts/enable-maintenance-mode.sh
# Retorna 503 para novas requisi√ß√µes

# 2. Aguardar requisi√ß√µes em andamento finalizarem
# Verificar que n√£o h√° requisi√ß√µes ativas
curl https://api.example.com/metrics | grep agent_active_requests
# Esperado: agent_active_requests 0

# 3. Parar aplica√ß√£o
# Op√ß√£o A: systemd
sudo systemctl stop agente-api

# Op√ß√£o B: Docker
docker-compose -f docker-compose.prod.yml down

# Op√ß√£o C: Kubernetes
kubectl scale deployment agente-api --replicas=0

# 4. Verificar que processo parou
ps aux | grep agente

# 5. Verificar logs para erros
tail -100 /var/log/agente/app.log
```

### 3.2 Deploy de Nova Vers√£o

**Estrat√©gia:** Canary Deployment (deploy gradual)

```bash
# 1. PR√â-DEPLOY: Verificar checklist
# - [ ] Todos testes passando no CI
# - [ ] Coverage >= 80%
# - [ ] Security scan passou
# - [ ] Documenta√ß√£o atualizada
# - [ ] Changelog atualizado
# - [ ] Runbook revisado se necess√°rio

# 2. Backup do banco de dados
./scripts/backup-database.sh
# Salvo em: /backups/db_YYYY-MM-DD_HH-MM.sql

# 3. Deploy Canary (5% tr√°fego)
./scripts/deploy-canary.sh v1.3.0 5%

# Ou manualmente no Kubernetes:
kubectl set image deployment/agente-api \
  agente-api=registry.example.com/agente-api:v1.3.0 \
  --record

kubectl patch deployment agente-api -p \
  '{"spec":{"replicas":1}}'  # 1 pod = ~5% do tr√°fego

# 4. MONITORAR por 2-4 horas
# Verificar dashboard: https://grafana.example.com/d/agent-overview
# Verificar m√©tricas:
#   - Error rate < 1%
#   - Response time p95 < 2s
#   - No alertas cr√≠ticos

# 5. Se est√°vel, aumentar para 25%
kubectl scale deployment agente-api --replicas=3  # 25%
# Monitorar por 1-2h

# 6. Se est√°vel, aumentar para 50%
kubectl scale deployment agente-api --replicas=6  # 50%
# Monitorar por 1h

# 7. Se est√°vel, completar para 100%
kubectl scale deployment agente-api --replicas=12  # 100%

# 8. Remover vers√£o antiga
kubectl delete deployment agente-api-old

# 9. Valida√ß√£o p√≥s-deploy
./scripts/smoke-test.sh
# Testa endpoints cr√≠ticos

# 10. Comunicar deploy completo
# Postar no Slack #deploys
```

**Se Algo Der Errado:**
```bash
# ROLLBACK IMEDIATO
kubectl rollout undo deployment/agente-api

# Ou para vers√£o espec√≠fica
kubectl rollout undo deployment/agente-api --to-revision=2

# Verificar rollback
kubectl rollout status deployment/agente-api

# Investigar causa
kubectl logs deployment/agente-api --previous
```

### 3.3 Rollback

```bash
# 1. Identificar vers√£o para rollback
kubectl rollout history deployment/agente-api

# Output:
# REVISION  CHANGE-CAUSE
# 1         Deploy v1.2.0
# 2         Deploy v1.3.0 (current)
# 3         Deploy v1.3.1

# 2. Rollback para revis√£o espec√≠fica
kubectl rollout undo deployment/agente-api --to-revision=1

# Ou rollback para vers√£o anterior
kubectl rollout undo deployment/agente-api

# 3. Verificar rollback em progresso
kubectl rollout status deployment/agente-api
# Esperado: "deployment "agente-api" successfully rolled out"

# 4. Validar vers√£o
curl https://api.example.com/version
# Esperado: {"version": "1.2.0"}

# 5. Validar funcionalidade
./scripts/smoke-test.sh

# 6. Monitorar m√©tricas
# Verificar que error rate voltou ao normal

# 7. Comunicar rollback
# Postar no Slack + criar postmortem
```

### 3.4 Escalar Recursos

#### Scale Up (Vertical Scaling)

```bash
# Aumentar recursos de CPU/mem√≥ria

# Kubernetes:
kubectl patch deployment agente-api -p \
  '{"spec":{"template":{"spec":{"containers":[{
    "name":"agente-api",
    "resources":{
      "requests":{"cpu":"2","memory":"4Gi"},
      "limits":{"cpu":"4","memory":"8Gi"}
    }
  }]}}}}'

# Docker Compose:
# Editar docker-compose.yml:
deploy:
  resources:
    limits:
      cpus: '4'
      memory: 8G

# Reiniciar
docker-compose up -d
```

#### Scale Out (Horizontal Scaling)

```bash
# Aumentar n√∫mero de inst√¢ncias

# Kubernetes:
kubectl scale deployment agente-api --replicas=20

# Verificar
kubectl get pods -l app=agente-api

# Auto-scaling (HPA)
kubectl autoscale deployment agente-api \
  --cpu-percent=70 \
  --min=5 \
  --max=50
```

### 3.5 Acessar Logs

```bash
# Logs em produ√ß√£o (√∫ltimos 100 linhas)
sudo journalctl -u agente-api -n 100

# Logs em tempo real
sudo journalctl -u agente-api -f

# Logs Docker
docker logs -f agente-api --tail 100

# Logs Kubernetes
kubectl logs -f deployment/agente-api

# Logs de pod espec√≠fico
kubectl logs pod-name -c agente-api

# Logs de todos os pods
kubectl logs -l app=agente-api --all-containers

# Logs anteriores (se crashou)
kubectl logs pod-name --previous

# Filtrar logs (erro)
kubectl logs deployment/agente-api | grep ERROR

# Exportar logs para an√°lise
kubectl logs deployment/agente-api --since=1h > logs_last_hour.txt
```

### 3.6 Acessar Banco de Dados

```bash
# PostgreSQL - Conectar
psql -h localhost -U agente_user -d agente_ia

# Queries √∫teis:

-- Ver conversas recentes
SELECT id, user_id, created_at, status
FROM conversations
ORDER BY created_at DESC
LIMIT 10;

-- Ver leads criados hoje
SELECT id, email, score, created_at
FROM leads
WHERE created_at >= CURRENT_DATE
ORDER BY score DESC;

-- Ver estat√≠sticas
SELECT
  DATE(created_at) as date,
  COUNT(*) as total_conversations,
  AVG(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) * 100 as completion_rate
FROM conversations
WHERE created_at >= CURRENT_DATE - INTERVAL '7 days'
GROUP BY DATE(created_at)
ORDER BY date;

-- Verificar tamanho do banco
SELECT pg_size_pretty(pg_database_size('agente_ia'));

-- Ver queries lentas
SELECT query, calls, mean_exec_time, max_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;

# Backup manual
pg_dump -h localhost -U agente_user agente_ia > backup_$(date +%Y%m%d_%H%M%S).sql

# Restore
psql -h localhost -U agente_user agente_ia < backup_20240120_153045.sql
```

### 3.7 Acessar Redis

```bash
# Conectar ao Redis
redis-cli -h localhost -p 6379

# Comandos √∫teis:

# Ver informa√ß√µes gerais
INFO

# Ver uso de mem√≥ria
INFO memory

# Ver todas as keys (CUIDADO em produ√ß√£o!)
KEYS *

# Ver keys com padr√£o
KEYS conversation:*

# Ver valor de uma key
GET conversation:abc-123

# Ver TTL de uma key
TTL conversation:abc-123

# Deletar key
DEL conversation:abc-123

# Limpar cache (CUIDADO!)
FLUSHDB  # Limpa database atual
FLUSHALL # Limpa todas databases

# Monitorar comandos em tempo real
MONITOR

# Ver estat√≠sticas
INFO stats

# Ver hit rate do cache
INFO stats | grep keyspace_hits
INFO stats | grep keyspace_misses
```

---

## 4. Procedimentos de Incidente

### 4.1 Processo Geral de Resposta

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 INCIDENTE DETECTADO                 ‚îÇ
‚îÇ         (Alerta, Usu√°rio, Monitoring)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            1. ACKNOWLEDGE (< 5 min)                 ‚îÇ
‚îÇ  - Confirmar recebimento do alerta                  ‚îÇ
‚îÇ  - Postar no Slack #incidents                       ‚îÇ
‚îÇ  - Iniciar timer                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            2. ASSESS (< 10 min)                     ‚îÇ
‚îÇ  - Qual a severidade? (P0, P1, P2)                  ‚îÇ
‚îÇ  - Quantos usu√°rios afetados?                       ‚îÇ
‚îÇ  - Sistema est√° up ou down?                         ‚îÇ
‚îÇ  - Verificar dashboard e logs                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            3. MITIGATE (< 30 min)                   ‚îÇ
‚îÇ  - Aplicar solu√ß√£o tempor√°ria (workaround)          ‚îÇ
‚îÇ  - Objetivo: restaurar servi√ßo                      ‚îÇ
‚îÇ  - N√£o precisa ser a solu√ß√£o final                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            4. RESOLVE                               ‚îÇ
‚îÇ  - Identificar root cause                           ‚îÇ
‚îÇ  - Aplicar fix definitivo                           ‚îÇ
‚îÇ  - Validar que problema foi resolvido               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            5. DOCUMENT                              ‚îÇ
‚îÇ  - Atualizar incident ticket                        ‚îÇ
‚îÇ  - Comunicar stakeholders                           ‚îÇ
‚îÇ  - Agendar postmortem (se P0/P1)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4.2 Severidade de Incidentes

| Prioridade | Descri√ß√£o | Resposta | Exemplo |
|------------|-----------|----------|---------|
| **P0 - Cr√≠tico** | Sistema down ou degrada√ß√£o severa | 15 min | Sistema completamente inacess√≠vel |
| **P1 - Alto** | Funcionalidade importante afetada | 2 horas | Error rate >5%, integra√ß√µes down |
| **P2 - M√©dio** | Problema menor, workaround existe | 1 dia √∫til | Performance degradada, logs faltando |
| **P3 - Baixo** | Problema cosm√©tico ou menor | Best effort | Typo em mensagem, m√©trica faltando |

### 4.3 Comunica√ß√£o Durante Incidentes

#### P0 - Cr√≠tico

```markdown
# Template de Comunica√ß√£o P0

**Canal:** Slack #incidents + Email stakeholders

**Mensagem Inicial (< 5 min):**
üî• INCIDENTE P0 - Sistema Down
- Detectado √†s: 14:32 BRT
- Impacto: Sistema completamente inacess√≠vel
- Investigando: @eng-oncall
- Status page: https://status.example.com
- Thread para updates: [link]

**Updates Regulares (a cada 15-30 min):**
üîÑ UPDATE 14:45 - Investiga√ß√£o em andamento
- Root cause identificado: Database connection pool esgotado
- A√ß√£o em andamento: Aumentando pool size
- ETA: 15 minutos

**Resolu√ß√£o:**
‚úÖ RESOLVIDO 15:10 - Sistema restaurado
- Dura√ß√£o: 38 minutos
- Root cause: Connection leak em c√≥digo
- Fix aplicado: Rollback para v1.2.0
- Monitorando: Pr√≥ximas 2 horas
- Postmortem: Agendado para amanh√£ 10h
```

#### P1 - Alto

```markdown
**Canal:** Slack #incidents

‚ö†Ô∏è INCIDENTE P1 - Error rate elevado
- Detectado √†s: 14:32 BRT
- Impacto: 10% dos requests falhando
- Investigando: @eng-oncall
- Updates: A cada 1h
```

### 4.4 Checklist de Resposta R√°pida

Quando alerta chegar, execute na ordem:

```bash
# 1. ACKNOWLEDGE (1 min)
# - Confirmar alerta no PagerDuty
# - Postar no Slack: "Investigando incidente X"

# 2. VERIFICAR STATUS GERAL (2 min)
curl https://api.example.com/health
# Se retornar 200 OK: problema √© intermitente
# Se retornar erro/timeout: sistema down

# 3. VERIFICAR DASHBOARD (2 min)
# Abrir: https://grafana.example.com/d/agent-overview
# Verificar:
# - Request rate (tr√°fego anormal?)
# - Error rate (spike de erros?)
# - Response time (lat√™ncia alta?)
# - System resources (CPU/mem√≥ria alta?)

# 4. VERIFICAR LOGS (3 min)
kubectl logs deployment/agente-api --tail=100 | grep ERROR
# Procurar por:
# - Stack traces
# - Erros de conex√£o (DB, Redis, LLM)
# - Timeouts
# - Exce√ß√µes n√£o tratadas

# 5. VERIFICAR DEPEND√äNCIAS (2 min)
# PostgreSQL
kubectl get pods -l app=postgresql  # Pods rodando?
# Redis
kubectl get pods -l app=redis       # Pods rodando?
# LLM API
curl https://api.openai.com/v1/models  # API respondendo?

# 6. DECIS√ÉO R√ÅPIDA (<10 min total)
# - Se conseguiu identificar causa: Aplicar fix
# - Se n√£o conseguiu: Escalar para senior engineer
# - Se sistema down: Considerar rollback
```

---

## 5. Guia de Troubleshooting

### 5.1 √Årvore de Decis√£o - Sistema Down

```
Sistema n√£o responde?
‚îÇ
‚îú‚îÄ API Gateway responde?
‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ N√ÉO ‚Üí Verificar Nginx/ALB
‚îÇ  ‚îÇ        ‚îî‚îÄ> Logs: /var/log/nginx/error.log
‚îÇ  ‚îÇ        ‚îî‚îÄ> Status: systemctl status nginx
‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ SIM ‚Üí API responde?
‚îÇ            ‚îÇ
‚îÇ            ‚îú‚îÄ N√ÉO ‚Üí Verificar Agent API
‚îÇ            ‚îÇ        ‚îî‚îÄ> Pods: kubectl get pods
‚îÇ            ‚îÇ        ‚îî‚îÄ> Logs: kubectl logs deployment/agente-api
‚îÇ            ‚îÇ        ‚îî‚îÄ> Health: curl /health
‚îÇ            ‚îÇ
‚îÇ            ‚îî‚îÄ SIM ‚Üí Problema intermitente
‚îÇ                     ‚îî‚îÄ> Ver Se√ß√£o 5.3
```

### 5.2 Problemas Comuns e Solu√ß√µes

#### Problema: "Sistema n√£o responde" (HTTP 503/504)

**Diagn√≥stico:**
```bash
# 1. Verificar se pods est√£o rodando
kubectl get pods -l app=agente-api

# Se STATUS != Running:
kubectl describe pod POD_NAME

# 2. Verificar logs
kubectl logs deployment/agente-api --tail=50

# 3. Verificar recursos
kubectl top pods -l app=agente-api
```

**Solu√ß√µes:**

```bash
# SOLU√á√ÉO 1: Restart pods (se OOM ou crash)
kubectl rollout restart deployment/agente-api

# SOLU√á√ÉO 2: Scale up (se CPU/mem√≥ria alta)
kubectl scale deployment agente-api --replicas=20

# SOLU√á√ÉO 3: Verificar health das depend√™ncias
# PostgreSQL
kubectl exec -it postgres-pod -- psql -U user -c "SELECT 1"

# Redis
kubectl exec -it redis-pod -- redis-cli ping
```

#### Problema: "Error rate alto" (>5%)

**Diagn√≥stico:**
```bash
# 1. Ver erros nos logs
kubectl logs deployment/agente-api | grep ERROR | tail -50

# 2. Identificar padr√£o
# - Todos erros iguais? (problema espec√≠fico)
# - Erros variados? (problema geral)

# 3. Verificar m√©tricas
curl https://api.example.com/metrics | grep agent_errors
```

**Solu√ß√µes por tipo de erro:**

```bash
# ERRO: "Database connection failed"
# ‚Üí PostgreSQL down ou connection pool esgotado
# Verificar:
kubectl get pods -l app=postgresql
# Aumentar connection pool:
kubectl set env deployment/agente-api DB_POOL_SIZE=50

# ERRO: "Redis connection timeout"
# ‚Üí Redis down ou rede lenta
kubectl get pods -l app=redis
kubectl logs deployment/redis

# ERRO: "LLM API rate limit"
# ‚Üí Muitas chamadas ao LLM
# Verificar cache hit rate:
redis-cli INFO stats | grep keyspace_hits
# Aumentar cache se hit rate < 60%

# ERRO: "Timeout waiting for response"
# ‚Üí LLM API lento
# Ver lat√™ncia do LLM:
kubectl logs deployment/agente-api | grep "LLM latency"
# Considerar usar modelo mais r√°pido ou aumentar timeout
```

#### Problema: "Response time alto" (P95 >3s)

**Diagn√≥stico:**
```bash
# 1. Ver distribui√ß√£o de lat√™ncias
curl https://api.example.com/metrics | grep agent_response_time

# 2. Identificar gargalo com tracing
# Ver traces no Grafana Tempo ou similar

# 3. Verificar slow queries
kubectl exec -it postgres-pod -- psql -U user -d agente_ia -c \
  "SELECT query, mean_exec_time FROM pg_stat_statements
   ORDER BY mean_exec_time DESC LIMIT 10;"
```

**Solu√ß√µes:**
```bash
# SOLU√á√ÉO 1: Otimizar queries lentas
# Adicionar √≠ndices se necess√°rio

# SOLU√á√ÉO 2: Aumentar cache
# Verificar hit rate
redis-cli INFO stats | grep hit_rate

# SOLU√á√ÉO 3: Scale out
kubectl scale deployment agente-api --replicas=20

# SOLU√á√ÉO 4: Usar LLM mais r√°pido
# Editar config para usar gpt-3.5-turbo ao inv√©s de gpt-4
kubectl set env deployment/agente-api DEFAULT_MODEL=gpt-3.5-turbo
```

#### Problema: "Integra√ß√£o com CRM falhando"

**Diagn√≥stico:**
```bash
# 1. Verificar logs de integra√ß√£o
kubectl logs deployment/agente-api | grep "CRM"

# 2. Testar API do CRM manualmente
curl -H "Authorization: Bearer $CRM_API_KEY" \
  https://api.salesforce.com/services/data/v57.0/

# 3. Verificar fila de retry
redis-cli LLEN crm_retry_queue
```

**Solu√ß√µes:**
```bash
# SOLU√á√ÉO 1: CRM API temporariamente down
# ‚Üí Verificar status do CRM
curl https://status.salesforce.com

# ‚Üí Ativar fallback (fila de retry est√° ativa?)
kubectl logs deployment/agente-api | grep "fallback"

# SOLU√á√ÉO 2: API Key expirada
# ‚Üí Regenerar API key no CRM
# ‚Üí Atualizar secret no Kubernetes
kubectl create secret generic crm-credentials \
  --from-literal=api-key=NEW_KEY \
  --dry-run=client -o yaml | kubectl apply -f -

# ‚Üí Restart para pegar novo secret
kubectl rollout restart deployment/agente-api

# SOLU√á√ÉO 3: Rate limit do CRM
# ‚Üí Adicionar rate limiting no client
# ‚Üí Aumentar intervalo entre retries
```

#### Problema: "Alto uso de mem√≥ria" (>85%)

**Diagn√≥stico:**
```bash
# 1. Ver uso atual
kubectl top pods -l app=agente-api

# 2. Ver hist√≥rico
# Abrir Grafana: https://grafana.example.com
# Dashboard: Agent API - Resources

# 3. Identificar memory leak (se uso crescente)
kubectl logs deployment/agente-api | grep "memory"
```

**Solu√ß√µes:**
```bash
# SOLU√á√ÉO IMEDIATA: Restart pods
kubectl rollout restart deployment/agente-api

# SOLU√á√ÉO 1: Aumentar mem√≥ria dispon√≠vel
kubectl patch deployment agente-api -p \
  '{"spec":{"template":{"spec":{"containers":[{
    "name":"agente-api",
    "resources":{"limits":{"memory":"8Gi"}}
  }]}}}}'

# SOLU√á√ÉO 2: Otimizar c√≥digo
# - Limitar tamanho de cache em mem√≥ria
# - Limpar objetos n√£o usados
# - Usar generators ao inv√©s de listas

# SOLU√á√ÉO 3: Investigar leak
# Adicionar memory profiling temporariamente
kubectl set env deployment/agente-api MEMORY_PROFILING=true
# Analisar profile depois
```

### 5.3 Problemas Intermitentes

**Sintoma:** Alguns requests falham, outros funcionam

**Diagn√≥stico:**
```bash
# 1. Verificar se √© problema de load balancing
# Ver distribui√ß√£o de erros por pod
kubectl logs -l app=agente-api --prefix=true | grep ERROR

# 2. Ver se algum pod espec√≠fico tem problemas
kubectl get pods -l app=agente-api
kubectl logs POD_NAME | grep ERROR

# 3. Verificar rate limiting
curl https://api.example.com/metrics | grep rate_limit_exceeded

# 4. Verificar timeouts
curl https://api.example.com/metrics | grep timeout
```

**Solu√ß√µes:**
```bash
# SOLU√á√ÉO 1: Pod espec√≠fico com problema
# Identificar pod problem√°tico
kubectl logs POD_NAME | grep ERROR | wc -l

# Deletar pod problem√°tico (ser√° recriado)
kubectl delete pod POD_NAME

# SOLU√á√ÉO 2: Rate limiting muito agressivo
# Aumentar limites
kubectl set env deployment/agente-api \
  RATE_LIMIT_PER_MINUTE=200

# SOLU√á√ÉO 3: Timeout muito baixo
kubectl set env deployment/agente-api \
  REQUEST_TIMEOUT=30
```

### 5.4 Comandos de Diagn√≥stico R√°pido

```bash
# HEALTH CHECK completo
./scripts/health-check.sh

# Ou manualmente:
curl https://api.example.com/health          # API health
curl https://api.example.com/health/db       # Database health
curl https://api.example.com/health/redis    # Redis health
curl https://api.example.com/health/llm      # LLM API health

# M√âTRICAS principais
curl https://api.example.com/metrics | grep -E "(agent_requests_total|agent_errors_total|agent_response_time)"

# LOGS com contexto
kubectl logs deployment/agente-api --tail=100 | grep -B 3 -A 3 ERROR

# TOP consumers de recursos
kubectl top pods --sort-by=memory
kubectl top pods --sort-by=cpu

# REDE - Verificar conectividade
kubectl exec -it POD_NAME -- curl -v https://api.openai.com
kubectl exec -it POD_NAME -- nc -zv postgres-service 5432
kubectl exec -it POD_NAME -- nc -zv redis-service 6379
```

**Refer√™ncia Completa:** `/docs/guias/troubleshooting.md`

---

## 6. Monitoramento e Alertas

### 6.1 Dashboards Principais

#### Dashboard: Agent Overview
**URL:** `https://grafana.example.com/d/agent-overview`

**Pain√©is principais:**
- Request Rate (requisi√ß√µes/min)
- Error Rate (%)
- Response Time (p50, p95, p99)
- Active Users
- System Resources (CPU, mem√≥ria)

**Como interpretar:**
```
Request Rate spike?
‚îî‚îÄ> Tr√°fego leg√≠timo ou ataque? Verificar User-Agents

Error Rate >1%?
‚îî‚îÄ> Ver logs: kubectl logs deployment/agente-api | grep ERROR

Response Time p95 >2s?
‚îî‚îÄ> Verificar:
    - LLM latency
    - Database slow queries
    - Cache hit rate
```

#### Dashboard: Business Metrics
**URL:** `https://grafana.example.com/d/agent-business`

**Pain√©is principais:**
- Conversions (leads/dia)
- CSAT Score
- Engagement Rate
- Handoff Rate

#### Dashboard: LLM Usage
**URL:** `https://grafana.example.com/d/agent-llm`

**Pain√©is principais:**
- Token Usage (input/output)
- Cost per Day
- Model Distribution
- Intent Accuracy

### 6.2 Alertas Cr√≠ticos (P0)

| Alerta | Threshold | A√ß√£o Imediata |
|--------|-----------|---------------|
| **SystemDown** | up==0 por 1 min | Verificar pods, verificar logs, considerar restart |
| **HighErrorRate** | Error rate >10% por 5 min | Ver logs, identificar erro, rollback se necess√°rio |
| **DatabaseDown** | pg_up==0 por 1 min | Verificar PostgreSQL, verificar rede, escalar para DBA |
| **RedisDown** | redis_up==0 por 1 min | Verificar Redis, sistema continua mas sem cache |
| **HighResponseTime** | p99 >10s por 10 min | Ver LLM latency, DB queries, considerar scale out |

### 6.3 Alertas Altos (P1)

| Alerta | Threshold | A√ß√£o (2h) |
|--------|-----------|-----------|
| **HighResponseTimeP95** | p95 >3s por 15 min | Investigar gargalos, otimizar queries |
| **ElevatedErrorRate** | Error rate 5-10% por 10 min | Identificar padr√£o de erros |
| **LowIntentAccuracy** | Accuracy <85% por 1h | Revisar prompts, analisar conversas |
| **HighMemoryUsage** | Mem√≥ria >85% por 10 min | Verificar leaks, considerar scale up |

### 6.4 Como Responder a Alertas

```bash
# QUANDO ALERTA CHEGAR:

# 1. Acknowledge no PagerDuty (< 1 min)
# Confirmar recebimento

# 2. Abrir Dashboard relevante (< 2 min)
# Ex: SystemDown ‚Üí Dashboard Agent Overview

# 3. Verificar logs (< 3 min)
kubectl logs deployment/agente-api --tail=100 | grep ERROR

# 4. Avaliar severidade (< 5 min)
# - Sistema down? ‚Üí P0
# - Funcionalidade afetada? ‚Üí P1
# - Performance degradada? ‚Üí P1/P2

# 5. Aplicar fix ou escalar (< 15 min para P0)
# Ver se√ß√£o espec√≠fica do alerta em:
# /templates/monitoramento/alertas.yaml

# 6. Atualizar stakeholders
# Postar no Slack #incidents

# 7. Resolver alerta
# Silenciar no Prometheus/AlertManager quando resolvido
```

**Refer√™ncia Completa:** `/templates/monitoramento/alertas.yaml`

---

## 7. Tarefas de Manuten√ß√£o

### 7.1 Di√°rias

```bash
# Executar a cada manh√£ (9h)

# 1. Verificar sa√∫de do sistema
./scripts/daily-health-check.sh

# Ou manualmente:
# - Abrir dashboard Agent Overview
# - Verificar error rate < 0.5%
# - Verificar response time p95 < 2s
# - Verificar uptime >= 99.5%

# 2. Revisar alertas das √∫ltimas 24h
# Ver: https://alertmanager.example.com

# 3. Verificar custos
curl https://api.example.com/metrics | grep cost_usd_total
# Comparar com budget di√°rio (target: <$400)

# 4. Revisar top erros
kubectl logs deployment/agente-api --since=24h | grep ERROR | sort | uniq -c | sort -rn | head -10

# 5. Verificar espa√ßo em disco
kubectl exec -it POD_NAME -- df -h
# Alerta se >80%
```

### 7.2 Semanais

```bash
# Executar toda segunda-feira

# 1. Review de m√©tricas de neg√≥cio
# - Conversion rate
# - CSAT score
# - Handoff rate
# - Intent accuracy
# Ver: https://grafana.example.com/d/agent-business

# 2. Backup verification
# Verificar que backups di√°rios est√£o sendo feitos
ls -lh /backups/db_* | tail -7

# Testar restore de backup mais recente (em staging)
./scripts/test-backup-restore.sh

# 3. Atualizar depend√™ncias
# Verificar atualiza√ß√µes de seguran√ßa
pip list --outdated
npm outdated  # Se houver frontend

# 4. Revisar logs de seguran√ßa
kubectl logs deployment/agente-api --since=7d | grep -E "(injection|unauthorized|suspicious)"

# 5. Limpar dados antigos
# Conversas >90 dias
psql -d agente_ia -c "DELETE FROM conversations WHERE created_at < NOW() - INTERVAL '90 days';"

# Logs >30 dias
find /var/log/agente -name "*.log" -mtime +30 -delete
```

### 7.3 Mensais

```bash
# Executar primeiro dia do m√™s

# 1. Review de capacidade
# - Uso m√©dio de CPU/mem√≥ria
# - Crescimento de tr√°fego
# - Necessidade de scale up/out
# Decis√£o: Ajustar recursos se necess√°rio

# 2. Review de custos
# - Total gasto no m√™s (LLM + infra)
# - Custo por conversa
# - ROI do projeto
# Relat√≥rio para stakeholders

# 3. Update de documenta√ß√£o
# - Runbook (este arquivo)
# - Arquitetura
# - Processos
# Verificar se est√° atualizado

# 4. Disaster recovery drill
# Simular falha e testar procedimento de recovery
./scripts/dr-drill.sh

# 5. Security audit
# - Revisar API keys (rotar se necess√°rio)
# - Revisar permiss√µes
# - Scan de vulnerabilidades
./scripts/security-scan.sh

# 6. Performance tuning
# - Identificar queries lentas
# - Adicionar √≠ndices se necess√°rio
# - Otimizar prompts
```

### 7.4 Trimestrais

```bash
# 1. Revis√£o de arquitetura
# - Avaliar tech debt
# - Planejar melhorias
# - Atualizar roadmap

# 2. Load testing
# Verificar que sistema aguenta tr√°fego esperado
./scripts/load-test.sh

# 3. Update de vers√µes maiores
# - Python
# - PostgreSQL
# - Redis
# Planejar em ambiente de staging primeiro

# 4. Treinamento do time
# - Novo membros: Runbook walkthrough
# - Time todo: Simula√ß√£o de incidentes
```

---

## 8. Procedimentos de Emerg√™ncia

### 8.1 Sistema Completamente Down

**OBJETIVO:** Restaurar servi√ßo o mais r√°pido poss√≠vel

```bash
# PASSO 1: Avaliar situa√ß√£o (2 min)
curl https://api.example.com/health
# N√£o responde? Sistema down.

# PASSO 2: Verificar pods (1 min)
kubectl get pods -l app=agente-api
# Todos em CrashLoopBackOff? Problema grave.

# PASSO 3: Ver logs (2 min)
kubectl logs deployment/agente-api --tail=50
# Identificar erro cr√≠tico

# PASSO 4: DECIS√ÉO R√ÅPIDA (<5 min total)

# OP√á√ÉO A: Erro conhecido? Aplicar fix conhecido
# Ex: Config errada
kubectl set env deployment/agente-api VARIABLE=correct_value
kubectl rollout restart deployment/agente-api

# OP√á√ÉO B: Problema de recurso? Scale up
kubectl scale deployment agente-api --replicas=20

# OP√á√ÉO C: N√£o sabe a causa? ROLLBACK
kubectl rollout undo deployment/agente-api

# OP√á√ÉO D: Rollback n√£o funciona? Usar vers√£o est√°vel conhecida
kubectl set image deployment/agente-api \
  agente-api=registry.example.com/agente-api:v1.2.0-stable

# PASSO 5: Verificar restaura√ß√£o (3 min)
watch -n 5 'curl -s https://api.example.com/health || echo "Still down"'

# PASSO 6: Comunicar (2 min)
# Postar no Slack #incidents:
# "Sistema restaurado. Dura√ß√£o: X minutos. Investigando root cause."

# PASSO 7: Monitorar (30 min)
# Verificar dashboard que m√©tricas voltaram ao normal

# PASSO 8: Post-incident
# Agendar postmortem
# Documentar timeline
# Identificar a√ß√µes corretivas
```

### 8.2 Database Irrecuper√°vel

**CEN√ÅRIO:** PostgreSQL corrompido, n√£o inicia

```bash
# PASSO 1: Avaliar dano
kubectl logs pod/postgresql-0

# PASSO 2: Tentar restart
kubectl delete pod postgresql-0
# Aguardar pod recriar e ver se inicia

# PASSO 3: Se n√£o funcionar, RESTORE de backup

# 3.1. Criar novo database vazio
kubectl exec -it postgresql-0 -- createdb agente_ia_new

# 3.2. Restaurar √∫ltimo backup
kubectl cp /backups/latest.sql postgresql-0:/tmp/backup.sql
kubectl exec -it postgresql-0 -- \
  psql agente_ia_new < /tmp/backup.sql

# 3.3. Verificar integridade
kubectl exec -it postgresql-0 -- \
  psql agente_ia_new -c "SELECT COUNT(*) FROM conversations;"

# 3.4. Apontar aplica√ß√£o para novo database
kubectl set env deployment/agente-api \
  DATABASE_NAME=agente_ia_new

# 3.5. Restart aplica√ß√£o
kubectl rollout restart deployment/agente-api

# PASSO 4: Comunicar perda de dados (se houver)
# "Restaurado a partir de backup de [timestamp]"
# "Dados entre [X] e [Y] foram perdidos"

# PASSO 5: RCA - Root Cause Analysis
# - O que causou corrup√ß√£o?
# - Como prevenir?
# - Atualizar runbook
```

### 8.3 Ataque DDoS em Andamento

**SINTOMAS:**
- Request rate 10x acima do normal
- Erro rate alto
- Response time alt√≠ssimo
- Alertas de rate limiting

```bash
# PASSO 1: Confirmar ataque (3 min)
# Ver dashboard
# Request rate anormal? De quais IPs?

# Ver logs
kubectl logs deployment/agente-api | grep rate_limit_exceeded

# Ver top IPs
kubectl logs deployment/agente-api | grep -oE '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' | sort | uniq -c | sort -rn | head -20

# PASSO 2: Mitigar IMEDIATAMENTE (<10 min)

# 2.1. Bloquear IPs atacantes no API Gateway
# Nginx:
sudo nano /etc/nginx/conf.d/blacklist.conf
# Adicionar:
deny 1.2.3.4;
deny 5.6.7.8;

sudo nginx -t && sudo systemctl reload nginx

# Ou via cloud provider (melhor)
# AWS WAF:
aws wafv2 update-ip-set \
  --id IP_SET_ID \
  --addresses 1.2.3.4/32 5.6.7.8/32

# 2.2. Reduzir rate limits temporariamente
kubectl set env deployment/agente-api \
  RATE_LIMIT_PER_MINUTE=10  # Muito restritivo

# 2.3. Ativar modo manuten√ß√£o parcial
# Bloquear novos usu√°rios, manter usu√°rios autenticados
kubectl set env deployment/agente-api \
  MAINTENANCE_MODE=partial

# PASSO 3: Escalar recursos se sistema ainda est√° respondendo
kubectl scale deployment agente-api --replicas=50

# PASSO 4: Habilitar CDN/DDoS protection
# Cloudflare, AWS Shield, etc

# PASSO 5: Comunicar
# Postar no Slack #incidents + #security

# PASSO 6: Monitorar
# Verificar que ataque foi mitigado
# Request rate voltou ao normal?

# PASSO 7: Post-incident
# - Documentar IPs atacantes
# - Melhorar defesas
# - Considerar Cloudflare/AWS Shield permanentemente
```

### 8.4 Data Breach Suspeito

**SINTOMAS:**
- Acessos n√£o autorizados
- Dados sens√≠veis vazados
- Atividade suspeita nos logs

```bash
# PASSO 1: ISOLAR IMEDIATAMENTE
# Desconectar sistema de integra√ß√µes
kubectl set env deployment/agente-api \
  ENABLE_INTEGRATIONS=false

# PASSO 2: Coletar evid√™ncias
# N√ÉO deletar logs!
# Copiar todos logs para an√°lise forense
kubectl logs deployment/agente-api --all-containers --since=24h > incident_logs_$(date +%Y%m%d).txt

# Copiar logs do API Gateway
sudo cp -r /var/log/nginx/access.log /tmp/incident_logs/

# PASSO 3: Notificar IMEDIATAMENTE
# - CISO/Security team
# - Legal
# - DPO (LGPD)

# PASSO 4: Avaliar extens√£o
# - Quais dados foram acessados?
# - Quais usu√°rios foram afetados?
# - Como acesso foi obtido?

# PASSO 5: Conter
# - Resetar todas API keys
# - For√ßar logout de todos usu√°rios
# - Revogar tokens comprometidos

# PASSO 6: N√ÉO RESTAURAR at√© investiga√ß√£o completa
# Sistema fica offline at√© OK do security team

# PASSO 7: Seguir plano de resposta a incidentes de seguran√ßa
# Ver: /docs/seguranca/incident-response-plan.md
```

### 8.5 LLM Provider Completamente Down

**CEN√ÅRIO:** OpenAI/Anthropic API inacess√≠vel

```bash
# PASSO 1: Confirmar que √© problema deles
curl https://status.openai.com
# Ou https://status.anthropic.com

# PASSO 2: Ativar fallback IMEDIATAMENTE

# Op√ß√£o A: Usar provider alternativo
kubectl set env deployment/agente-api \
  LLM_PROVIDER=anthropic  # Se OpenAI down

# Op√ß√£o B: Usar respostas pre-programadas
kubectl set env deployment/agente-api \
  FALLBACK_MODE=true

# PASSO 3: Comunicar usu√°rios
# "Estamos com instabilidade tempor√°ria. Respostas podem ser limitadas."

# PASSO 4: Monitorar status do provider
# Aguardar volta

# PASSO 5: Quando voltar, desativar fallback
kubectl set env deployment/agente-api \
  LLM_PROVIDER=openai \
  FALLBACK_MODE=false

# PASSO 6: Post-incident
# - Considerar multi-provider strategy permanente
# - Melhorar fallbacks
```

---

## 9. Escala√ß√£o

### 9.1 Quando Escalar?

**Escalar IMEDIATAMENTE se:**
- Sistema down por >15 minutos e voc√™ n√£o sabe resolver
- Suspeita de security breach
- Data loss
- N√£o consegue mitigar incidente P0 em 30 minutos

**Escalar em 2h se:**
- Incidente P1 sem progresso
- Problema complexo que requer expertise espec√≠fica
- M√∫ltiplos problemas simult√¢neos

### 9.2 Cadeia de Escala√ß√£o

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  N√≠vel 1: Engineer On-Call                  ‚îÇ
‚îÇ  - Responde a alertas                       ‚îÇ
‚îÇ  - Aplica runbooks                          ‚îÇ
‚îÇ  - Resolve incidentes simples               ‚îÇ
‚îÇ  Contato: @oncall no Slack                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ Escalar ap√≥s 30min sem resolu√ß√£o
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  N√≠vel 2: Senior Engineer / Tech Lead       ‚îÇ
‚îÇ  - Problemas complexos                      ‚îÇ
‚îÇ  - Decis√µes arquiteturais                   ‚îÇ
‚îÇ  - Coordena resposta a incidentes           ‚îÇ
‚îÇ  Contato: +55 11 99999-1234 (Tech Lead)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ Escalar se impacto cr√≠tico ou >1h
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  N√≠vel 3: Engineering Manager / CTO         ‚îÇ
‚îÇ  - Incidentes que afetam neg√≥cio            ‚îÇ
‚îÇ  - Decis√µes de budget/recursos              ‚îÇ
‚îÇ  - Comunica√ß√£o com stakeholders C-level     ‚îÇ
‚îÇ  Contato: +55 11 99999-5678 (CTO)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LATERAL: Especialistas                     ‚îÇ
‚îÇ  - DBA: Problemas de database               ‚îÇ
‚îÇ  - Security: Suspeita de breach             ‚îÇ
‚îÇ  - ML Engineer: Problemas de prompts/LLM    ‚îÇ
‚îÇ  - DevOps: Problemas de infra               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 9.3 Informa√ß√µes para Incluir na Escala√ß√£o

```markdown
**Template de Escala√ß√£o**

üö® ESCALANDO INCIDENTE

**Prioridade:** P0 / P1 / P2
**In√≠cio:** 14:32 BRT
**Dura√ß√£o at√© agora:** 45 minutos

**Resumo:**
Sistema apresentando error rate de 15%. Tentei X, Y, Z sem sucesso.

**Impacto:**
- 500 usu√°rios afetados
- Convers√µes paradas
- Revenue impact: ~R$ 5k/hora

**O que j√° tentei:**
1. Restart dos pods - N√£o funcionou
2. Rollback para v1.2.0 - Ainda com erros
3. Verificado DB/Redis - Ambos OK

**Logs/Evid√™ncias:**
[Anexar logs relevantes]

**Dashboard:**
https://grafana.example.com/d/agent-overview

**Preciso de ajuda com:**
Root cause n√£o identificado, erro intermitente.

**Pr√≥ximos passos se n√£o houver resposta em 15min:**
Vou colocar sistema em manuten√ß√£o.

cc: @tech-lead @senior-engineer
```

---

## 10. Runbooks Espec√≠ficos

### 10.1 Runbook: Carga Alta (Traffic Spike)

**Sintomas:**
- Request rate 3x-5x acima do normal
- Response time aumentando
- CPU/mem√≥ria alta

**Diagn√≥stico:**
```bash
# 1. Ver tr√°fego atual vs hist√≥rico
# Dashboard Grafana: Request rate panel

# 2. Verificar se √© tr√°fego leg√≠timo
kubectl logs deployment/agente-api | grep User-Agent | sort | uniq -c

# 3. Verificar recursos
kubectl top pods -l app=agente-api
```

**Resposta:**
```bash
# SE TR√ÅFEGO LEG√çTIMO (evento, marketing, etc):

# 1. Scale out imediatamente
kubectl scale deployment agente-api --replicas=30

# 2. Verificar que novos pods est√£o saud√°veis
kubectl get pods -l app=agente-api
# Aguardar todos STATUS = Running

# 3. Monitorar m√©tricas
# Response time deve voltar ao normal em 2-5 min

# 4. Ativar auto-scaling se ainda n√£o ativo
kubectl autoscale deployment agente-api \
  --cpu-percent=70 --min=10 --max=50

# SE TR√ÅFEGO MALICIOSO (ver Se√ß√£o 8.3 - DDoS)
```

### 10.2 Runbook: Database Issues

**Sintomas:**
- Erros "database connection failed"
- Queries lentas
- Connection pool exhausted

**Diagn√≥stico:**
```bash
# 1. Verificar se database est√° up
kubectl get pods -l app=postgresql

# 2. Verificar conex√µes ativas
kubectl exec -it postgres-pod -- psql -U user -d agente_ia -c \
  "SELECT count(*) FROM pg_stat_activity;"

# 3. Ver queries lentas em andamento
kubectl exec -it postgres-pod -- psql -U user -d agente_ia -c \
  "SELECT pid, now() - query_start as duration, query
   FROM pg_stat_activity
   WHERE state = 'active'
   ORDER BY duration DESC;"

# 4. Verificar espa√ßo em disco
kubectl exec -it postgres-pod -- df -h
```

**Resposta:**
```bash
# PROBLEMA: Connection pool exhausted

# Solu√ß√£o tempor√°ria: Aumentar pool size
kubectl set env deployment/agente-api \
  DB_POOL_SIZE=50 \
  DB_MAX_OVERFLOW=20

kubectl rollout restart deployment/agente-api

# Solu√ß√£o permanente: Investigar connection leaks


# PROBLEMA: Queries lentas

# 1. Identificar query problem√°tica (j√° executado acima)

# 2. Matar query se necess√°rio
kubectl exec -it postgres-pod -- psql -U user -d agente_ia -c \
  "SELECT pg_terminate_backend(PID);"

# 3. Adicionar √≠ndice se necess√°rio
kubectl exec -it postgres-pod -- psql -U user -d agente_ia -c \
  "CREATE INDEX CONCURRENTLY idx_conversations_user_id ON conversations(user_id);"

# 4. Atualizar estat√≠sticas
kubectl exec -it postgres-pod -- psql -U user -d agente_ia -c \
  "ANALYZE;"


# PROBLEMA: Espa√ßo em disco cheio (>90%)

# 1. Limpar dados antigos
kubectl exec -it postgres-pod -- psql -U user -d agente_ia -c \
  "DELETE FROM conversations WHERE created_at < NOW() - INTERVAL '90 days';"

# 2. Vacuum
kubectl exec -it postgres-pod -- psql -U user -d agente_ia -c \
  "VACUUM FULL;"

# 3. Aumentar disco (se necess√°rio)
# Depende do provider (AWS EBS, GCP PD, etc)
```

### 10.3 Runbook: LLM Issues

**Sintomas:**
- Rate limit errors
- High latency (>10s)
- Custos disparados

**Diagn√≥stico:**
```bash
# 1. Ver erros de LLM nos logs
kubectl logs deployment/agente-api | grep "LLM" | grep ERROR

# 2. Ver m√©tricas de uso
curl https://api.example.com/metrics | grep llm_

# 3. Ver lat√™ncia do LLM
kubectl logs deployment/agente-api | grep "LLM latency" | tail -20

# 4. Ver custos
curl https://api.example.com/metrics | grep cost_usd
```

**Resposta:**
```bash
# PROBLEMA: Rate limit exceeded

# Solu√ß√£o 1: Aumentar cache agressivamente
kubectl set env deployment/agente-api \
  CACHE_TTL=3600  # 1 hora

# Solu√ß√£o 2: Usar tier maior da API (se dispon√≠vel)
# Ou espa√ßar requests com rate limiter


# PROBLEMA: High latency

# Solu√ß√£o 1: Usar modelo mais r√°pido
kubectl set env deployment/agente-api \
  DEFAULT_MODEL=gpt-3.5-turbo  # Mais r√°pido que gpt-4

# Solu√ß√£o 2: Reduzir max_tokens
kubectl set env deployment/agente-api \
  MAX_TOKENS=300

# Solu√ß√£o 3: Implementar timeout
kubectl set env deployment/agente-api \
  LLM_TIMEOUT=10


# PROBLEMA: Custos muito altos

# 1. Ver distribui√ß√£o de uso por modelo
curl https://api.example.com/metrics | grep llm_tokens_by_model

# 2. A√ß√µes imediatas:
# - Aumentar cache (reduz chamadas)
kubectl set env deployment/agente-api CACHE_TTL=3600

# - Usar modelo mais barato para queries simples
kubectl set env deployment/agente-api \
  SIMPLE_QUERY_MODEL=gpt-3.5-turbo

# - Reduzir max_tokens
kubectl set env deployment/agente-api MAX_TOKENS=300

# - Otimizar prompts (menos tokens no input)

# 3. An√°lise mais profunda:
# - Quais conversas est√£o consumindo mais?
# - H√° conversas muito longas?
# - Prompts muito grandes?
```

### 10.4 Runbook: Integra√ß√£o CRM Down

**Sintomas:**
- Erros "CRM API failed"
- Leads n√£o sendo criados
- Fila de retry crescendo

**Diagn√≥stico:**
```bash
# 1. Ver logs de integra√ß√£o
kubectl logs deployment/agente-api | grep CRM

# 2. Testar API do CRM diretamente
curl -H "Authorization: Bearer $CRM_API_KEY" \
  https://api.salesforce.com/services/data/v57.0/

# 3. Ver status do CRM
curl https://status.salesforce.com

# 4. Ver tamanho da fila de retry
redis-cli LLEN crm_retry_queue
```

**Resposta:**
```bash
# SE CRM EST√Å DOWN (problema deles):

# 1. Verificar que fallback est√° ativo
kubectl logs deployment/agente-api | grep "CRM fallback active"
# Deve ver: "CRM unavailable, queuing for retry"

# 2. Monitorar fila de retry
watch -n 30 'redis-cli LLEN crm_retry_queue'

# 3. Quando CRM voltar, processar fila
# Fila ser√° processada automaticamente
# Ou force processamento:
kubectl exec -it agente-api-pod -- python scripts/process_retry_queue.py

# 4. Verificar que leads foram sincronizados
# Ver logs para confirma√ß√µes


# SE CRM EST√Å UP mas integra√ß√£o falhando:

# 1. Verificar API key
kubectl get secret crm-credentials -o jsonpath='{.data.api-key}' | base64 -d

# 2. Testar manualmente com essa key
curl -H "Authorization: Bearer $API_KEY" \
  https://api.salesforce.com/services/data/v57.0/

# 3. Se key expirada, regenerar e atualizar
kubectl create secret generic crm-credentials \
  --from-literal=api-key=NEW_KEY \
  --dry-run=client -o yaml | kubectl apply -f -

kubectl rollout restart deployment/agente-api

# 4. Se problema de formato de dados, verificar logs
kubectl logs deployment/agente-api | grep "CRM request"
# Verificar formato do payload
```

### 10.5 Runbook: Deploy Falhou

**Sintomas:**
- Pods em CrashLoopBackOff ap√≥s deploy
- Error rate disparou ap√≥s deploy
- Nova vers√£o n√£o est√° funcionando

**Resposta:**
```bash
# A√á√ÉO IMEDIATA: ROLLBACK

# 1. Rollback (< 2 min)
kubectl rollout undo deployment/agente-api

# 2. Verificar que rollback completou
kubectl rollout status deployment/agente-api

# 3. Verificar que sistema voltou ao normal
curl https://api.example.com/health
# Ver dashboard de m√©tricas

# 4. Comunicar
# Postar no Slack: "Deploy v1.3.0 falhou, rollback executado"

# 5. INVESTIGAR causa

# Ver logs da vers√£o que falhou
kubectl logs deployment/agente-api --previous

# Erros comuns:
# - Config errada (vari√°vel de ambiente faltando)
# - Migra√ß√£o de DB n√£o rodou
# - Depend√™ncia quebrada
# - Bug no c√≥digo

# 6. CORRIGIR e tentar novamente

# Se config errada:
# - Corrigir configmap/secret
# - Deploy novamente

# Se bug no c√≥digo:
# - Fix do bug
# - Novo deploy (com mais cuidado)

# Se migra√ß√£o de DB:
# - Rodar migra√ß√£o manualmente
# - Deploy novamente
```

---

## 11. Checklist de On-Call

### 11.1 In√≠cio do Turno On-Call

```markdown
- [ ] Verificar que estou recebendo alertas (teste no PagerDuty)
- [ ] Ler resumo do turno anterior (handoff notes)
- [ ] Ver incidentes abertos ou em andamento
- [ ] Verificar sa√∫de geral do sistema (dashboard)
- [ ] Verificar alertas ativos (mesmo que n√£o cr√≠ticos)
- [ ] Ter acesso VPN/SSH/kubectl configurado e testado
- [ ] Ter runbook (este documento) aberto e revisado
- [ ] Verificar calend√°rio (algum deploy agendado?)
- [ ] Laptop carregado, internet est√°vel
```

### 11.2 Durante o Turno

```markdown
- [ ] Checar dashboard 2-3x por dia
- [ ] Responder alertas em <15 min (P0) ou <2h (P1)
- [ ] Documentar a√ß√µes tomadas
- [ ] Comunicar no Slack quando resolver incidentes
- [ ] Escalar se necess√°rio (n√£o hesite!)
- [ ] Manter laptop/celular pr√≥ximo
```

### 11.3 Fim do Turno On-Call

```markdown
- [ ] Escrever handoff notes para pr√≥ximo on-call
- [ ] Mencionar incidentes ativos ou problemas em andamento
- [ ] Mencionar tarefas que ficaram pendentes
- [ ] Transferir PagerDuty para pr√≥ximo on-call
- [ ] Postar no Slack que turno terminou
```

### 11.4 Handoff Template

```markdown
**On-Call Handoff - [Data]**

**De:** @engineer-saindo
**Para:** @engineer-entrando

**Status Geral:** ‚úÖ Est√°vel / ‚ö†Ô∏è Issues menores / üî• Incidente ativo

**Incidentes nas √∫ltimas 24h:**
- 14:30 - Error rate spike (P1) - Resolvido com rollback
- 18:45 - Redis down (P0) - Resolvido com restart

**Problemas em andamento:**
- Nenhum / Integra√ß√£o com CRM intermitente, monitorando

**Alertas ativos (n√£o cr√≠ticos):**
- HighCacheHitRate - Normal, aguardando

**Manuten√ß√µes planejadas:**
- Amanh√£ 3am - Manuten√ß√£o do PostgreSQL (5 min downtime)

**Observa√ß√µes:**
- Traffic 20% acima do normal devido a campanha de marketing
- Cache hit rate melhorou ap√≥s ajustes

**Contatos √∫teis:**
- DBA de plant√£o: @dba-oncall
- CTO: +55 11 99999-5678 (emerg√™ncias)

**Documentos importantes:**
- Runbook: /docs/operacao/runbook.md
- Dashboard: https://grafana.example.com/d/agent-overview
```

---

## 12. Contatos e Recursos

### 12.1 Contatos de Emerg√™ncia

| Fun√ß√£o | Nome | Contato | Quando Usar |
|--------|------|---------|-------------|
| **On-Call Engineer** | Rotativo | @oncall no Slack | Primeira linha de resposta |
| **Tech Lead** | [NOME] | +55 11 99999-1234 | Incidentes P0 sem resolu√ß√£o em 30min |
| **Engineering Manager** | [NOME] | +55 11 99999-2345 | Decis√µes de budget/recursos |
| **CTO** | [NOME] | +55 11 99999-5678 | Incidentes cr√≠ticos de neg√≥cio |
| **DBA** | [NOME] | +55 11 99999-3456 | Problemas de database |
| **Security Lead** | [NOME] | +55 11 99999-4567 | Suspeita de breach |
| **DevOps Lead** | [NOME] | +55 11 99999-6789 | Problemas de infraestrutura |

### 12.2 Canais de Comunica√ß√£o

| Canal | Uso | Urg√™ncia |
|-------|-----|----------|
| **#incidents** | Incidentes ativos P0/P1 | URGENTE |
| **#alerts** | Todos os alertas (P0/P1/P2) | NORMAL |
| **#deploys** | Comunica√ß√£o de deploys | NORMAL |
| **#engineering** | Discuss√µes t√©cnicas | NORMAL |
| **PagerDuty** | Alertas P0 (24/7) | CR√çTICO |

### 12.3 URLs Importantes

```markdown
**Production:**
- API: https://api.example.com
- Health: https://api.example.com/health
- Metrics: https://api.example.com/metrics
- Status Page: https://status.example.com

**Monitoring:**
- Grafana: https://grafana.example.com
  - Dashboard Principal: /d/agent-overview
  - Dashboard Neg√≥cio: /d/agent-business
  - Dashboard LLM: /d/agent-llm
- Prometheus: https://prometheus.example.com
- AlertManager: https://alertmanager.example.com

**Logs:**
- Kibana: https://kibana.example.com
- Datadog: https://app.datadoghq.com

**CI/CD:**
- GitHub Actions: https://github.com/company/agent-ia/actions
- ArgoCD: https://argocd.example.com

**Infrastructure:**
- AWS Console: https://console.aws.amazon.com
- Kubernetes Dashboard: https://k8s.example.com

**Documentation:**
- Internal Wiki: https://wiki.example.com
- Runbook (este doc): /docs/operacao/runbook.md
- Architecture: /docs/arquitetura.md
```

### 12.4 Credenciais e Acessos

```markdown
**Localiza√ß√£o de Secrets:**

- **Kubernetes Secrets:**
  kubectl get secrets -n production

- **AWS Secrets Manager:**
  aws secretsmanager list-secrets --region us-east-1

- **Senha Master (1Password/LastPass):**
  Solicitar ao Tech Lead

**Acessos Necess√°rios:**
- [ ] VPN corporativa
- [ ] kubectl configurado (production)
- [ ] AWS CLI configurado
- [ ] Acesso SSH aos servidores (se aplic√°vel)
- [ ] PagerDuty account
- [ ] Grafana account
- [ ] GitHub (repository access)
- [ ] Slack (canais relevantes)
```

### 12.5 Ferramentas Essenciais

```bash
# Instalar ferramentas necess√°rias:

# kubectl (Kubernetes CLI)
brew install kubectl

# AWS CLI
brew install awscli

# PostgreSQL client
brew install postgresql

# Redis client
brew install redis

# jq (JSON parser)
brew install jq

# Verificar instala√ß√£o
kubectl version --client
aws --version
psql --version
redis-cli --version
jq --version
```

### 12.6 Documenta√ß√£o de Refer√™ncia

```markdown
**Documenta√ß√£o Interna:**
- Arquitetura: /docs/arquitetura.md
- Guias: /docs/guias/
- Processos: /docs/processos/
- Troubleshooting: /docs/guias/troubleshooting.md
- Metodologia: /docs/metodologia/OVERVIEW.md

**Documenta√ß√£o Externa:**
- Kubernetes: https://kubernetes.io/docs/
- PostgreSQL: https://www.postgresql.org/docs/
- Redis: https://redis.io/documentation
- FastAPI: https://fastapi.tiangolo.com/
- OpenAI API: https://platform.openai.com/docs/
- Prometheus: https://prometheus.io/docs/

**Runbooks Relacionados:**
- Security Incident Response: /docs/seguranca/incident-response-plan.md
- Disaster Recovery: /docs/operacao/disaster-recovery.md
- Database Runbook: /docs/operacao/database-runbook.md
```

---

## Ap√™ndices

### A. Gloss√°rio de Termos

| Termo | Defini√ß√£o |
|-------|-----------|
| **P0/P1/P2** | Prioridades de incidente (P0=Cr√≠tico, P1=Alto, P2=M√©dio) |
| **RTO** | Recovery Time Objective - Tempo m√°ximo de downtime aceit√°vel |
| **RPO** | Recovery Point Objective - Perda de dados m√°xima aceit√°vel |
| **Canary Deploy** | Deploy gradual, come√ßando com pequeno % de tr√°fego |
| **Rollback** | Reverter para vers√£o anterior |
| **Runbook** | Documento com procedimentos operacionais |
| **Postmortem** | An√°lise p√≥s-incidente para aprender e melhorar |
| **SLA** | Service Level Agreement - Acordo de n√≠vel de servi√ßo |
| **SLO** | Service Level Objective - Objetivo de n√≠vel de servi√ßo |
| **On-Call** | Engenheiro de plant√£o respons√°vel por responder alertas |
| **Guardrails** | Valida√ß√µes de seguran√ßa em inputs/outputs do agente |
| **Handoff** | Transfer√™ncia de turno on-call |
| **Fallback** | Comportamento alternativo quando algo falha |

### B. Comandos R√°pidos (Cheat Sheet)

```bash
# HEALTH CHECK
curl https://api.example.com/health

# VER PODS
kubectl get pods -l app=agente-api

# LOGS (√∫ltimos 100 linhas)
kubectl logs deployment/agente-api --tail=100

# LOGS (tempo real)
kubectl logs -f deployment/agente-api

# RESTART
kubectl rollout restart deployment/agente-api

# SCALE
kubectl scale deployment agente-api --replicas=20

# ROLLBACK
kubectl rollout undo deployment/agente-api

# M√âTRICAS
curl https://api.example.com/metrics | grep agent_requests_total

# DATABASE
kubectl exec -it postgres-pod -- psql -U user -d agente_ia

# REDIS
kubectl exec -it redis-pod -- redis-cli

# TOP RECURSOS
kubectl top pods -l app=agente-api

# VER VERS√ÉO ATUAL
curl https://api.example.com/version
```

### C. Status Codes e Significados

| Status Code | Significado | A√ß√£o |
|-------------|-------------|------|
| **200 OK** | Requisi√ß√£o bem sucedida | Nenhuma |
| **400 Bad Request** | Input inv√°lido | Verificar valida√ß√£o de input |
| **401 Unauthorized** | Autentica√ß√£o falhou | Verificar API key |
| **429 Too Many Requests** | Rate limit excedido | Implementar backoff, verificar se √© ataque |
| **500 Internal Server Error** | Erro no servidor | Ver logs, identificar exce√ß√£o |
| **502 Bad Gateway** | Problema no gateway/LB | Verificar API Gateway/Nginx |
| **503 Service Unavailable** | Servi√ßo indispon√≠vel | Verificar pods, DB, Redis |
| **504 Gateway Timeout** | Timeout | Verificar lat√™ncia, scale out |

---

## Hist√≥rico de Vers√µes

| Vers√£o | Data | Autor | Mudan√ßas |
|--------|------|-------|----------|
| 1.0 | 2024-01-20 | Tech Team | Vers√£o inicial completa |

---

## Feedback e Melhorias

Este runbook √© um documento vivo. Se voc√™:
- Encontrou informa√ß√£o faltando
- Usou um procedimento que n√£o funcionou
- Tem sugest√£o de melhoria

**Por favor:**
1. Abra um PR com a corre√ß√£o/melhoria
2. Ou crie um issue no GitHub
3. Ou mencione no Slack #engineering

**Revis√£o:** Este runbook deve ser revisado mensalmente e atualizado sempre que houver mudan√ßas significativas no sistema.

---

**Lembre-se:**
- N√£o entre em p√¢nico
- Siga os procedimentos
- Comunique claramente
- Documente tudo
- Escale quando necess√°rio
- Aprenda com cada incidente

**Voc√™ n√£o est√° sozinho. O time est√° aqui para ajudar.**
